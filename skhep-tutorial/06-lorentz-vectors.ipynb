{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lorentz vectors, particle PDG IDs, jet-clustering, oh my!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Lorentz vectors\n",
    "\n",
    "In keeping with the \"many small packages\" philosophy, 2D/3D/Lorentz vectors are handled by a package named Vector. This is where you can find calculations like `deltaR` and coordinate transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vector\n",
    "\n",
    "one = vector.obj(px=1, py=0, pz=0)\n",
    "two = vector.obj(px=0, py=1, pz=1)\n",
    "\n",
    "one + two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one.deltaR(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "one.to_rhophieta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "two.to_rhophieta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "To fit in with the rest of the ecosystem, Vector must be an array-oriented library. Arrays of 2D/3D/Lorentz vectors are processed in bulk.\n",
    "\n",
    "`MomentumNumpy2D`, `MomentumNumpy3D`, `MomentumNumpy4D` are NumPy array subtypes: NumPy arrays can be *cast* to these types and get all the vector functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skhep_testdata, uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "\n",
    "tree = uproot.open(skhep_testdata.data_path(\"uproot-Zmumu.root\"))[\"events\"]\n",
    "\n",
    "one = ak.to_numpy(tree.arrays(filter_name=[\"E1\", \"p[xyz]1\"]))\n",
    "two = ak.to_numpy(tree.arrays(filter_name=[\"E2\", \"p[xyz]2\"]))\n",
    "\n",
    "one.dtype.names = (\"E\", \"px\", \"py\", \"pz\")\n",
    "two.dtype.names = (\"E\", \"px\", \"py\", \"pz\")\n",
    "\n",
    "one = one.view(vector.MomentumNumpy4D)\n",
    "two = two.view(vector.MomentumNumpy4D)\n",
    "\n",
    "one + two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "one.deltaR(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one.to_rhophieta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "two.to_rhophieta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "After `vector.register_awkward()` is called, `\"Momentum2D\"`, `\"Momentum3D\"`, `\"Momentum4D\"` are record names that Awkward Array will recognize to get all the vector functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.register_awkward()\n",
    "\n",
    "tree = uproot.open(skhep_testdata.data_path(\"uproot-HZZ.root\"))[\"events\"]\n",
    "\n",
    "array = tree.arrays(filter_name=[\"Muon_E\", \"Muon_P[xyz]\"])\n",
    "\n",
    "muons = ak.zip(\n",
    "    {\"px\": array.Muon_Px, \"py\": array.Muon_Py, \"pz\": array.Muon_Pz, \"E\": array.Muon_E},\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "mu1, mu2 = ak.unzip(ak.combinations(muons, 2))\n",
    "\n",
    "mu1 + mu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1.deltaR(mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.to_rhophieta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Particle properties and PDG identifiers\n",
    "\n",
    "The Particle library provides all of the particle masses, decay widths and more from the PDG.\n",
    "It further contains a series of tools to programmatically query particle properties and use several identification schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import particle\n",
    "from hepunits import GeV\n",
    "\n",
    "particle.Particle.findall(\"pi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_boson = particle.Particle.from_name(\"Z0\")\n",
    "z_boson.mass / GeV, z_boson.width / GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_boson.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle.Particle.from_pdgid(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle.Particle.findall(\n",
    "    lambda p: p.pdgid.is_meson and p.pdgid.has_strange and p.pdgid.has_charm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(particle.PDGID(211).info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdgid = particle.Corsika7ID(11).to_pdgid()\n",
    "particle.Particle.from_pdgid(pdgid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Jet clustering\n",
    "\n",
    "In a high-energy pp collision, for instance, a spray of hadrons is produced which is clustered into `jets' of particles and this method/process is called jet-clustering.  The anti-kt jet clustering algorithm is one such algorithm used to combine particles/hadrons that are close to each other into jets.\n",
    "\n",
    "Some people need to do jet-clustering at the analysis level. The fastjet package makes it possible to do that an (Awkward) array at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skhep_testdata, uproot\n",
    "import awkward as ak\n",
    "import particle\n",
    "from hepunits import GeV\n",
    "import vector\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "picodst = uproot.open(\n",
    "    \"https://pivarski-princeton.s3.amazonaws.com/pythia_ppZee_run17emb.picoDst.root:PicoDst\"\n",
    ")\n",
    "px, py, pz = ak.unzip(\n",
    "    picodst.arrays(filter_name=[\"Track/Track.mPMomentum[XYZ]\"], entry_stop=100)\n",
    ")\n",
    "\n",
    "probable_mass = particle.Particle.from_name(\"pi+\").mass / GeV\n",
    "\n",
    "pseudojets = ak.zip(\n",
    "    {\"px\": px, \"py\": py, \"pz\": pz, \"mass\": probable_mass}, with_name=\"Momentum4D\"\n",
    ")\n",
    "good_pseudojets = pseudojets[pseudojets.pt > 0.1]\n",
    "\n",
    "import fastjet\n",
    "\n",
    "jetdef = fastjet.JetDefinition(fastjet.antikt_algorithm, 1.0)\n",
    "\n",
    "clusterseq = fastjet.ClusterSequence(good_pseudojets, jetdef)\n",
    "clusterseq.inclusive_jets()\n",
    "\n",
    "ak.num(good_pseudojets), ak.num(clusterseq.inclusive_jets())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "This fastjet package uses Vector to get coordinate transformations and all the Lorentz vector methods you're accustomed to having in pseudo-jet objects. I used Particle to impute the mass of particles with only track-level information.\n",
    "\n",
    "See how all the pieces accumulate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
