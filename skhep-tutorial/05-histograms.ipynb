{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Histogram manipulations and fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Histogram libraries\n",
    "\n",
    "Mainstream Python has libraries for filling histograms.\n",
    "\n",
    "## NumPy\n",
    "\n",
    "NumPy, for instance, has an [np.histogram](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skhep_testdata, uproot\n",
    "\n",
    "tree = uproot.open(skhep_testdata.data_path(\"uproot-Zmumu.root\"))[\"events\"]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.histogram(tree[\"M\"].array())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Because of NumPy's prominence, this 2-tuple of arrays (bin contents and edges) is a widely recognized histogram format, though it lacks many of the features high-energy physicists expect (under/overflow, axis labels, uncertainties, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "\n",
    "Matplotlib also has a [plt.hist](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(tree[\"M\"].array());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "In addition to the same bin contents and edges as NumPy, Matplotlib includes a plottable graphic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Boost-histogram and hist\n",
    "\n",
    "![boost histogram](img/bh_logo.png)\n",
    "\n",
    "![hist](img/hist_logo.png)\n",
    "\n",
    "The main feature that these functions lack (without some effort) is refillability. High-energy physicists usually want to fill histograms with more data than can fit in memory, which means setting bin intervals on an empty container and filling it in batches (sequentially or in parallel).\n",
    "\n",
    "Boost-histogram is a library designed for that purpose. It is intended as an infrastructure component. You can explore its \"low-level\" functionality upon importing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boost_histogram as bh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "A more user-friendly layer (with plotting, for instance) is provided by a library called \"hist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hist\n",
    "\n",
    "h = hist.Hist(hist.axis.Regular(120, 60, 120, name=\"mass\"))\n",
    "\n",
    "h.fill(tree[\"M\"].array())\n",
    "\n",
    "h.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Universal Histogram Indexing (UHI)\n",
    "\n",
    "There is an attempt within Scikit-HEP to standardize what array-like slices mean for a histogram. ([See documentation](https://uhi.readthedocs.io/en/latest/indexing.html).)\n",
    "\n",
    "Naturally, integer slices should select a range of bins,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "h[10:110].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "but often you want to select bins by coordinate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit version\n",
    "# h[hist.loc(90) :].plot();\n",
    "\n",
    "# Short version\n",
    "h[90j:].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "or rebin by a factor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit version\n",
    "# h[:: hist.rebin(2)].plot();\n",
    "\n",
    "# Short version\n",
    "h[::2j].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "or sum over a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit version\n",
    "# h[hist.loc(80) : hist.loc(100) : sum]\n",
    "\n",
    "# Short version\n",
    "h[90j:100j:sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Things get more interesting when a histogram has multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import hist\n",
    "import awkward as ak\n",
    "\n",
    "picodst = uproot.open(\n",
    "    \"https://pivarski-princeton.s3.amazonaws.com/pythia_ppZee_run17emb.picoDst.root:PicoDst\"\n",
    ")\n",
    "\n",
    "vertexhist = hist.Hist(\n",
    "    hist.axis.Regular(600, -1, 1, label=\"x\"),\n",
    "    hist.axis.Regular(600, -1, 1, label=\"y\"),\n",
    "    hist.axis.Regular(40, -200, 200, label=\"z\"),\n",
    ")\n",
    "\n",
    "vertex_data = picodst.arrays(filter_name=\"*mPrimaryVertex[XYZ]\")\n",
    "\n",
    "vertexhist.fill(\n",
    "    ak.flatten(vertex_data[\"Event.mPrimaryVertexX\"]),\n",
    "    ak.flatten(vertex_data[\"Event.mPrimaryVertexY\"]),\n",
    "    ak.flatten(vertex_data[\"Event.mPrimaryVertexZ\"]),\n",
    ")\n",
    "\n",
    "vertexhist[:, :, sum].plot2d_full()\n",
    "vertexhist[-0.25j:0.25j, -0.25j:0.25j, sum].plot2d_full()\n",
    "vertexhist[sum, sum, :].plot()\n",
    "vertexhist[-0.25j:0.25j:sum, -0.25j:0.25j:sum, :].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "A histogram object can have more dimensions than you can reasonably visualizeâ€”you can slice, rebin, and project it into something visual later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Fitting histograms\n",
    "\n",
    "![iminuit](img/iminuit_logo.png)\n",
    "\n",
    "![zfit](img/zfit_logo.png)\n",
    "\n",
    "By directly writing a loss function in Minuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import iminuit.cost\n",
    "\n",
    "norm = len(h.axes[0].widths) / (h.axes[0].edges[-1] - h.axes[0].edges[0]) / h.sum()\n",
    "\n",
    "\n",
    "def f(x, background, mu, gamma):\n",
    "    return (\n",
    "        background\n",
    "        + (1 - background) * gamma**2 / ((x - mu) ** 2 + gamma**2) / np.pi / gamma\n",
    "    )\n",
    "\n",
    "\n",
    "loss = iminuit.cost.LeastSquares(\n",
    "    h.axes[0].centers, h.values() * norm, np.sqrt(h.variances()) * norm, f\n",
    ")\n",
    "loss.mask = h.variances() > 0\n",
    "\n",
    "minimizer = iminuit.Minuit(loss, background=0, mu=91, gamma=4)\n",
    "\n",
    "minimizer.migrad()\n",
    "minimizer.hesse()\n",
    "\n",
    "(h * norm).plot()\n",
    "plt.plot(loss.x, f(loss.x, *minimizer.values));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Or through zfit, a Pythonic RooFit-like fitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zfit\n",
    "\n",
    "binned_data = zfit.data.BinnedData.from_hist(h)\n",
    "\n",
    "binning = zfit.binned.RegularBinning(120, 60, 120, name=\"mass\")\n",
    "space = zfit.Space(\"mass\", binning=binning)\n",
    "\n",
    "background = zfit.Parameter(\"background\", 0)\n",
    "mu = zfit.Parameter(\"mu\", 91)\n",
    "gamma = zfit.Parameter(\"gamma\", 4)\n",
    "unbinned_model = zfit.pdf.SumPDF(\n",
    "    [zfit.pdf.Uniform(60, 120, space), zfit.pdf.Cauchy(mu, gamma, space)], [background]\n",
    ")\n",
    "\n",
    "model = zfit.pdf.BinnedFromUnbinnedPDF(unbinned_model, space)\n",
    "loss = zfit.loss.BinnedNLL(model, binned_data)\n",
    "\n",
    "minimizer = zfit.minimize.Minuit()\n",
    "result = minimizer.minimize(loss)\n",
    "\n",
    "binned_data.to_hist().plot(density=1)\n",
    "model.to_hist().plot(density=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
